{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Meade speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "import queue\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import urllib\n",
    "import util\n",
    "import os.path\n",
    "import datetime\n",
    "from os.path import join as pjoin\n",
    "import time\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://www.meade18.com/categorias/discursos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_soup(website):\n",
    "    '''\n",
    "    Takes a website and creates a soup.\n",
    "\n",
    "    Inputs:\n",
    "        website: a url\n",
    "\n",
    "    Outputs:\n",
    "        Soup object.\n",
    "    '''\n",
    "\n",
    "    sitio = util.get_request(website)\n",
    "    siitio = sitio.text.encode('UTF-16')\n",
    "    soup = bs4.BeautifulSoup(siitio, \"html5lib\")\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech extractor\n",
    "def extractor(url):\n",
    "    speech = \"\"\n",
    "    soup = build_soup(url)\n",
    "    for p in soup.find_all('p'):\n",
    "        speech += p.getText()\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds list of tuples (date,speech)\n",
    "def soup_to_links(soup, link_list):\n",
    "\n",
    "\n",
    "    for art in soup.find_all('article'):\n",
    "        if art.attrs['role'] == \"article\":\n",
    "            link = art.find('a')\n",
    "            url = link.get('href')\n",
    "            \n",
    "            speech = extractor(url)\n",
    "            \n",
    "            time = art.find('time')\n",
    "            date = time.get('datetime')[0:10]\n",
    "        \n",
    "            tup = [date, speech]\n",
    "            link_list.append(tup)\n",
    "\n",
    "    return(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the links with speeches\n",
    "all_sites = [website] * 18\n",
    "for i in range(1,18):\n",
    "    num = i+1\n",
    "    plug = str(num)\n",
    "    all_sites[i] = all_sites[i]+\"page/\" + plug +\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for site in all_sites:\n",
    "    soup = build_soup(site)\n",
    "    links = soup_to_links(soup, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and merging dataframes\n",
    "meade_df = pd.DataFrame(data, columns = ['date', 'speech']) \n",
    "meade_df.to_csv('meade.csv',  encoding='UTF-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
